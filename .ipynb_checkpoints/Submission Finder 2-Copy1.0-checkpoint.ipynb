{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl as xl\n",
    "import pprint as pp\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load xlsx file into Python\n",
    "wb = xl.load_workbook('input2.xlsx') #Open Input workbook\n",
    "journals = wb['journal_sheet'] #Open journals worksheet\n",
    "urls = wb[\"url_sheet\"]\n",
    "num_rows = len(tuple(journals.rows))\n",
    "\n",
    "#journal_sheet column map\n",
    "#Col 0/A = journal name\n",
    "#Col 1/B = Publisher\n",
    "#Col 2/C = ISSN\n",
    "#Col 3/D = EISSN\n",
    "#Col 4/E = Country\n",
    "#Col 5/F = Language\n",
    "#Col 6/G = Category\n",
    "#Col 7/H = Submission Guidelines URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAYLOR & FRANCIS INC\n",
      "WILEY\n",
      "SAGE PUBLICATIONS INC\n",
      "ELSEVIER\n",
      "CAMBRIDGE UNIV PRESS\n",
      "OXFORD UNIV PRESS\n",
      "WALTER DE GRUYTER GMBH\n",
      "JOHNS HOPKINS UNIV PRESS\n",
      "UNIV CHICAGO PRESS\n",
      "EMERALD GROUP PUBLISHING LTD\n",
      "BRILL ACADEMIC PUBLISHERS\n",
      "JOHN BENJAMINS PUBLISHING CO\n",
      "AMER PSYCHOLOGICAL ASSOC\n",
      "DUKE UNIV PRESS\n",
      "DE GRUYTER MOUTON\n",
      "ACADEMIC PRESS INC ELSEVIER SCIENCE\n",
      "PALGRAVE MACMILLAN LTD\n",
      "MIT PRESS\n",
      "BIOMED CENTRAL LTD\n",
      "EDINBURGH UNIV PRESS\n",
      "EDUCATIONAL PUBLISHING FOUNDATION-AMERICAN PSYCHOLOGICAL ASSOC\n",
      "UNIV CALIFORNIA PRESS\n",
      "HOGREFE & HUBER PUBLISHERS\n",
      "CONSEJO SUPERIOR INVESTIGACIONES CIENTIFICAS-CSIC\n",
      "ANNUAL REVIEWS\n",
      "UNIV TORONTO PRESS INC\n",
      "PENN STATE UNIV PRESS\n",
      "UNIV ILLINOIS PRESS\n",
      "INFORMS\n",
      "PRESSES UNIV FRANCE\n",
      "KARGER\n",
      "INDIANA UNIV PRESS\n",
      "FRANZ STEINER VERLAG GMBH\n",
      "ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD\n",
      "W B SAUNDERS CO-ELSEVIER INC\n",
      "UNIV TEXAS PRESS\n",
      "PEETERS\n",
      "LIVERPOOL UNIV PRESS\n",
      "TAYLOR & FRANCIS INC\n",
      "WILEY\n",
      "SAGE PUBLICATIONS INC\n",
      "ELSEVIER\n",
      "CAMBRIDGE UNIV PRESS\n",
      "OXFORD UNIV PRESS\n",
      "WALTER DE GRUYTER GMBH\n",
      "JOHNS HOPKINS UNIV PRESS\n",
      "UNIV CHICAGO PRESS\n",
      "EMERALD GROUP PUBLISHING LTD\n",
      "BRILL ACADEMIC PUBLISHERS\n",
      "JOHN BENJAMINS PUBLISHING CO\n",
      "AMER PSYCHOLOGICAL ASSOC\n",
      "DUKE UNIV PRESS\n",
      "DE GRUYTER MOUTON\n",
      "ACADEMIC PRESS INC ELSEVIER SCIENCE\n",
      "PALGRAVE MACMILLAN LTD\n",
      "MIT PRESS\n",
      "BIOMED CENTRAL LTD\n",
      "EDINBURGH UNIV PRESS\n",
      "EDUCATIONAL PUBLISHING FOUNDATION-AMERICAN PSYCHOLOGICAL ASSOC\n",
      "UNIV CALIFORNIA PRESS\n",
      "HOGREFE & HUBER PUBLISHERS\n",
      "CONSEJO SUPERIOR INVESTIGACIONES CIENTIFICAS-CSIC\n",
      "ANNUAL REVIEWS\n",
      "UNIV TORONTO PRESS INC\n",
      "PENN STATE UNIV PRESS\n",
      "UNIV ILLINOIS PRESS\n",
      "INFORMS\n",
      "PRESSES UNIV FRANCE\n",
      "KARGER\n",
      "INDIANA UNIV PRESS\n",
      "FRANZ STEINER VERLAG GMBH\n",
      "ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD\n",
      "W B SAUNDERS CO-ELSEVIER INC\n",
      "UNIV TEXAS PRESS\n",
      "PEETERS\n",
      "LIVERPOOL UNIV PRESS\n"
     ]
    }
   ],
   "source": [
    "#Iterate through the url sheet to find the submission page URL outlines\n",
    "\n",
    "access_methods = {}\n",
    "publishers = []\n",
    "url_methods = []\n",
    "\n",
    "for row in urls.iter_rows(min_row=2, max_col=8, max_row=40):\n",
    "    if row[0].value != 'SPRINGER':\n",
    "        publishers.append(row[0].value)\n",
    "        url_methods.append(row[7].value)\n",
    "        print(row[0].value)\n",
    "    \n",
    "    \n",
    "access_methods = dict(zip(publishers,url_methods))\n",
    "\n",
    "home_access_methods = {}\n",
    "publishers = []\n",
    "url_methods = []\n",
    "\n",
    "for row in urls.iter_rows(min_row=2, max_col=8, max_row=40):\n",
    "    if row[0].value != 'SPRINGER':\n",
    "        publishers.append(row[0].value)\n",
    "        url_methods.append(row[4].value)\n",
    "        print(row[0].value)\n",
    "    \n",
    "    \n",
    "    \n",
    "home_access_methods = dict(zip(publishers,url_methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through journals and replace None Values with empty strings\n",
    "for row in journals.iter_rows(min_row=2, max_col=7, max_row=num_rows):\n",
    "    for col in row:\n",
    "        if col.value == None:\n",
    "            col.value = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(row, source, home_url):\n",
    "    #Alias varibles for readability\n",
    "    \n",
    "    journal = row[0]\n",
    "    publisher = row[1]\n",
    "    issn = row[2]\n",
    "    eissn = row[3]\n",
    "    target = row[7]\n",
    "    home_page = row[8]\n",
    "    #Check for each attribute in URL and replace with appropriate variable\n",
    "    #print(\"Source =\" + source)\n",
    "    \n",
    "    if \"ABBREVIATION\" in source:\n",
    "        try:\n",
    "            print(home_page.value)\n",
    "            print(home_url)\n",
    "            print(source)\n",
    "            x = home_page.value.split('/')\n",
    "            y = home_url.split('/')\n",
    "            z = source.split('/')\n",
    "            print(x[0::])\n",
    "            print(y[0::])\n",
    "            print(z[0::])\n",
    "            pos = (y.index(\"ABBREVIATION\"))\n",
    "            #print(pos)\n",
    "            abbreviation = x[pos]\n",
    "            #print(abbreviation)\n",
    "            temp = z.replace(\"ABBREVIATION\", abbreviation)\n",
    "            slash = '/'\n",
    "            target = slash.join(temp)\n",
    "            print('Success')\n",
    "        except:\n",
    "            print('Failure')\n",
    "        \n",
    "    if \"J_U_NAME\" in source:\n",
    "        #replace J_U_NAME with lowercase journal name and replace space with an underscore\n",
    "        temp_name = journal.value.lower().replace(\" \",\"_\")\n",
    "        target = source.replace(\"J_U_NAME\", temp_name)\n",
    "        source = target\n",
    "    if \"JNAME\" in source:\n",
    "        #Replace JNAME with lowercase journal name and replace space with hyphen\n",
    "        temp_name = journal.value.lower().replace(\" \", \"-\") \n",
    "        target = source.replace(\"JNAME\",temp_name)\n",
    "        source = target\n",
    "    if \"EISSN\" in source:\n",
    "        #Replace EISSN with actual EISSN, replacing space with hyphen\n",
    "        temp_name = eissn.value.replace(\"-\",\"\")\n",
    "        target = source.replace(\"EISSN\", temp_name)\n",
    "        source = target\n",
    "    if \"E_H_SSN\" in source:\n",
    "        #Replace EISSN with actual EISSN, keeping hyphens\n",
    "        temp_name = eissn.value\n",
    "        target = source.replace(\"E_H_SSN\", temp_name)\n",
    "        source = target\n",
    "    if \"ISSN\" in source:\n",
    "        #Replace ISSN with actual ISSN, replacing space with hyphen\n",
    "        temp_name = issn.value.replace(\"-\",\"\")\n",
    "        target = source.replace(\"ISSN\", temp_name)\n",
    "        source = target\n",
    "    if \"I_H_SSN\" in source:\n",
    "        #Replace ISSN with actual ISSN, keeping hyphens\n",
    "        temp_name = issn.value\n",
    "        target = source.replace(\"I_H_SSN\", temp_name)\n",
    "        source = target\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n",
      "Failure\n"
     ]
    }
   ],
   "source": [
    "#Iterate over all rows, find the URL outline and return the submission outline Page\n",
    "\n",
    "for row in journals.iter_rows(max_col=9, min_row=2, max_row=num_rows):\n",
    "    #Check if submission page has already been found, and if homepage hage has been found\n",
    "    #try:\n",
    "    #print(row[0].value)\n",
    "    if(row[1].value != 'SPRINGER' and row[1].value != 'TAYLOR & FRANCIS INC'):\n",
    "    \n",
    "        if(row[7].value == None and row[8].value[0:4] == 'http'):\n",
    "            #print('^^^ No Submission page, found homepage')\n",
    "            #if not found, and a homepage has been found\n",
    "            for key, value in home_access_methods.items():\n",
    "                #print(row[0].value)\n",
    "                if key == row[1].value: #if publisher names match list of identified access_methods\n",
    "                    for ikey,ivalue in access_methods.items():\n",
    "                        if key == ikey and value != None and ivalue != None:\n",
    "                            #print('1:' + access_methods[row[1].value] + '\\n2' + home_access_methods[row[1].value] + '\\n3' + row[8].value)\n",
    "                            x = get_url(row, access_methods[row[1].value], home_access_methods[row[1].value])#Pass row and url outline\n",
    "                            #print(\"=============================================\")\n",
    "                            #print(x.value)\n",
    "                            \n",
    "    #except:\n",
    "        #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save('input2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http:', '', 'www.apa.org', 'pubs', 'journals', 'per', '?tab=4']\n"
     ]
    }
   ],
   "source": [
    "x = 'per'\n",
    "y = ['http:', '', 'www.apa.org', 'pubs', 'journals', 'ABBREVIATION', '?tab=4']\n",
    "\n",
    "temp = [w.replace('ABBREVIATION', x) for w in y]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
