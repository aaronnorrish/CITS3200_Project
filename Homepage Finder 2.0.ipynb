{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dryscrape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4f083d7d6aa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdryscrape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dryscrape'"
     ]
    }
   ],
   "source": [
    "import openpyxl as xl\n",
    "import pprint as pp\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import time\n",
    "import dryscrape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load xlsx file into Python\n",
    "wb = xl.load_workbook('output.xlsx') #Open Input workbook\n",
    "journals = wb['journal_sheet'] #Open journals worksheet\n",
    "urls = wb[\"url_sheet\"]\n",
    "num_rows = len(tuple(journals.rows))\n",
    "\n",
    "#journal_sheet column map\n",
    "#Col 0/A = journal name\n",
    "#Col 1/B = Publisher\n",
    "#Col 2/C = ISSN\n",
    "#Col 3/D = EISSN\n",
    "#Col 4/E = Country\n",
    "#Col 5/F = Language\n",
    "#Col 6/G = Category\n",
    "#Col 7/H = Submission Guidelines URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(row, source):\n",
    "    #Alias varibles for readability\n",
    "    \n",
    "    journal = row[0]\n",
    "    publisher = row[1]\n",
    "    issn = row[2]\n",
    "    eissn = row[3]\n",
    "    target = row[8]\n",
    "    \n",
    "    #Check for each attribute in URL and replace with appropriate variable\n",
    "    \n",
    "    if \"J_U_NAME\" in source:\n",
    "        #replace J_U_NAME with lowercase journal name and replace space with an underscore\n",
    "        temp_name = journal.value.lower().replace(\" \",\"_\")\n",
    "        target = source.replace(\"J_U_NAME\", temp_name)\n",
    "        source = target\n",
    "    if \"JNAME\" in source:\n",
    "        #Replace JNAME with lowercase journal name and replace space with hyphen\n",
    "        temp_name = journal.value.lower().replace(\" \", \"-\") \n",
    "        target = source.replace(\"JNAME\",temp_name)\n",
    "        source = target\n",
    "    if \"EISSN\" in source:\n",
    "        #Replace EISSN with actual EISSN, replacing space with hyphen\n",
    "        temp_name = eissn.value.replace(\"-\",\"\")\n",
    "        target = source.replace(\"EISSN\", temp_name)\n",
    "        source = target\n",
    "    if \"E_H_SSN\" in source:\n",
    "        #Replace EISSN with actual EISSN, keeping hyphens\n",
    "        temp_name = eissn.value\n",
    "        target = source.replace(\"E_H_SSN\", temp_name)\n",
    "        source = target\n",
    "    if \"ISSN\" in source:\n",
    "        #Replace ISSN with actual ISSN, replacing space with hyphen\n",
    "        temp_name = issn.value.replace(\"-\",\"\")\n",
    "        target = source.replace(\"ISSN\", temp_name)\n",
    "        source = target\n",
    "    if \"I_H_SSN\" in source:\n",
    "        #Replace ISSN with actual ISSN, keeping hyphens\n",
    "        temp_name = issn.value\n",
    "        target = source.replace(\"I_H_SSN\", temp_name)\n",
    "        source = target\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://www.enable-javascript.com/\" rel=\"nofollow noopener\" target=\"_blank\">\n",
      "                        instructions how to enable JavaScript in your web browser</a>\n",
      "<a href=\"http://www.enable-javascript.com/\" rel=\"nofollow noopener\" target=\"_blank\">\n",
      "                        instructions how to enable JavaScript in your web browser</a>\n",
      "<a href=\"http://www.enable-javascript.com/\" rel=\"nofollow noopener\" target=\"_blank\">\n",
      "                        instructions how to enable JavaScript in your web browser</a>\n",
      "<a href=\"http://www.enable-javascript.com/\" rel=\"nofollow noopener\" target=\"_blank\">\n",
      "                        instructions how to enable JavaScript in your web browser</a>\n",
      "<a href=\"http://www.enable-javascript.com/\" rel=\"nofollow noopener\" target=\"_blank\">\n",
      "                        instructions how to enable JavaScript in your web browser</a>\n"
     ]
    }
   ],
   "source": [
    "#Iterate over all rows, find homepage\n",
    "#TAKES VERY VERY LONG\n",
    "home_page_url = \"https://www.researchgate.net/journal/I_H_SSN_J_U_NAME\"\n",
    "limit = 0 #recomended for testing\n",
    "\n",
    "#headers = requests.utils.default_headers() #Reduces change of blocking\n",
    "#headers.update({\n",
    " #   'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "  #  'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "   # 'accept-encoding': 'gzip, deflate, br',\n",
    "    #'accept-language': 'en-US,en:q=0.9'\n",
    "#})\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "}\n",
    "\n",
    "delays = [7, 4, 6, 2, 10, 19]\n",
    "\n",
    "\n",
    "for row in journals.iter_rows(max_col=9, min_row=2, max_row=num_rows):\n",
    "    if limit == 5:\n",
    "        break\n",
    "    #try:\n",
    "    delay = np.random.choice(delays)\n",
    "    time.sleep(delay)\n",
    "        \n",
    "    page = requests.get(get_url(row, home_page_url), headers=headers)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        print(link)\n",
    "        row[8].value = link.get('href')\n",
    "        limit +=1\n",
    "        \n",
    "   # except:\n",
    "    #    continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¶\n",
      "Â¶\n",
      "Â¶\n",
      "Locating Elements\n",
      "Â¶\n",
      "Â¶\n",
      "unittest\n",
      "Locating Elements\n",
      "Â¶\n",
      "\n",
      "\n",
      "\n",
      "1. Installation\n",
      "2. Getting Started\n",
      "2.1. Simple Usage\n",
      "2.2. Example Explained\n",
      "2.3. Using Selenium to write tests\n",
      "2.4. Walk through of the example\n",
      "2.5. Using Selenium with remote WebDriver\n",
      "3. Navigating\n",
      "4. Locating Elements\n",
      "5. Waits\n",
      "6. Page Objects\n",
      "7. WebDriver API\n",
      "8. Appendix: Frequently Asked Questions\n",
      "Documentation overview\n",
      "1. Installation\n",
      "3. Navigating\n",
      "Sphinx 1.6.5\n",
      "Alabaster 0.7.10\n",
      "Page source\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36',\n",
    "}\n",
    "page = requests.get(\"https://selenium-python.readthedocs.io/getting-started.html#simple-usage\", headers=headers)\n",
    "soup = BeautifulSoup(page.text,'html.parser')\n",
    "for link in soup.find_all(\"a\"):\n",
    "    print(link.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
